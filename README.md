# Nexora â€“ The AI That Codes, Thinks, and Learns From Its Own Mistakes

> â€œAn intelligent, modular AI system that plans, codes, validates, and refines itself â€” powered by a fine-tuned TinyLlama model.â€

![Nexora Banner](https://via.placeholder.com/1000x250?text=Nexora+AI+Assistant)

---

## ğŸ·ï¸ Badges

![Python](https://img.shields.io/badge/Python-3.11%2B-blue)
![Streamlit](https://img.shields.io/badge/Streamlit-1.50%2B-ff4b4b)
![Ollama](https://img.shields.io/badge/Ollama-Local%20LLM-green)
![License](https://img.shields.io/badge/License-MIT-yellow)
![Status](https://img.shields.io/badge/Build-Passing-success)

---

## ğŸš€ Overview

**Nexora** is an experimental **multi-agent AI assistant** built to explore the intersection of *autonomous reasoning*, *code generation*, and *self-improvement*.

Developed as a personal R&D project, Nexora can:

- ğŸ§© Understand complex prompts  
- ğŸ§­ Plan multi-step actions  
- ğŸ’» Generate, test, and refine code  
- ğŸ“š Conduct factual research  
- ğŸ“Š Measure its own reasoning complexity through **entropy tracking**

Built with **Python**, **Streamlit**, and a **fine-tuned TinyLlama model**, Nexora operates fully **offline** via **Ollama**, ensuring privacy, speed, and local inference.



## ğŸ§± Project Structure

<details>
<summary>Click to expand</summary>

```plaintext
assistant_hub/
â”‚
â”œâ”€â”€ streamlit_app.py              # Main UI entry point
â”œâ”€â”€ run_assistant.py              # Initializes backend + agents
â”‚
â”œâ”€â”€ core/                         # Core coordination layer
â”‚   â”œâ”€â”€ config.py
â”‚   â”œâ”€â”€ factory.py
â”‚   â”œâ”€â”€ dependency_injector.py
â”‚   â””â”€â”€ agent_coordinator.py
â”‚
â”œâ”€â”€ agents/                       # Specialized LLM-driven agents
â”‚   â”œâ”€â”€ proxy_agent.py
â”‚   â”œâ”€â”€ planner_agent.py
â”‚   â”œâ”€â”€ researcher_agent.py
â”‚   â”œâ”€â”€ coder_agent.py
â”‚   â”œâ”€â”€ validator_agent.py
â”‚   â””â”€â”€ code_validation_loop.py
â”‚
â”œâ”€â”€ tools/                        # Execution helpers and utilities
â”‚   â”œâ”€â”€ coding_tools.py
â”‚   â”œâ”€â”€ output_formatter.py
â”‚   â””â”€â”€ langchain_tools.py
â”‚
â”œâ”€â”€ ui/                           # Streamlit UI logic
â”‚   â”œâ”€â”€ helpers.py
â”‚   â””â”€â”€ views.py
â”‚
â”œâ”€â”€ models/                       # Fine-tuned TinyLlama GGUF model
â”‚   â””â”€â”€ tinyllama-codegen-q4_k_m.gguf
â”‚
â”œâ”€â”€ training/                     # LoRA fine-tuning scripts + datasets
â”‚   â”œâ”€â”€ fine_tuning_manager.py
â”‚   â”œâ”€â”€ collector.py
â”‚   â””â”€â”€ datasets/
â”‚
â””â”€â”€ reports/                      # Metrics, logs, and presentation
    â”œâ”€â”€ entropy_tracking_simulation.csv
    â””â”€â”€ Nexora_Presentation_Script.docx
````

</details>

---

## âš™ï¸ Core Features

| Feature                         | Description                                                                                            |
| ------------------------------- | ------------------------------------------------------------------------------------------------------ |
| ğŸ¤– **Multi-Agent Intelligence** | Planner, Researcher, Coder, and Validator agents collaborate autonomously.                             |
| ğŸ§  **Fine-Tuned Model**         | Based on `TinyLlama/TinyLlama-1.1B-Chat-v1.0`, fine-tuned with **LoRA + Unsloth** on *CodeAlpaca-20k*. |
| ğŸ’» **Offline Inference**        | Runs fully local in GGUF format (`q4_k_m`) via **Ollama**.                                             |
| ğŸ“ˆ **Entropy Tracking**         | Monitors task refinement, time, and â€œfrustrationâ€ to analyze reasoning complexity.                     |
| ğŸ’¬ **Interactive UI**           | Streamlit interface with chat memory, file uploads, and audio transcription.                           |
| ğŸ”Š **Voice & File Support**     | Upload audio, documents, or code directly into the interface.                                          |

---

## ğŸ§  Fine-Tuning Journey

| Step               | Description                                                            |
| ------------------ | ---------------------------------------------------------------------- |
| ğŸ§© **Base Model**  | TinyLlama/TinyLlama-1.1B-Chat-v1.0                                     |
| ğŸ§° **Dataset**     | sahil2801/CodeAlpaca-20k                                               |
| ğŸ§® **Method**      | LoRA fine-tuning with Unsloth                                          |
| â˜ï¸ **Environment** | Google Colab (T4 GPU)                                                  |
| ğŸ§  **Output**      | LoRA adapter (~45 MB) merged into TinyLlama                            |
| ğŸ’¾ **Format**      | GGUF (q4_k_m) for Ollama                                               |
| âš™ï¸ **Result**      | Locally running fine-tuned model optimized for code and planning tasks |

---

## ğŸ§ª Entropy Tracking (Experimental)

Every research or code-generation session logs:

* Task Description
* Number of Refinements
* Time Spent
* Errors Encountered
* Frustration Score

**Example report:**

| Task                   | Refinements | Time (min) | Errors | Frustration |
| ---------------------- | ----------- | ---------- | ------ | ----------- |
| Research AI Regulation | 4           | 11.0       | 2      | 5           |
| Climate Impact Study   | 2           | 6.0        | 0      | 2           |
| Code Debugging Loop    | 5           | 12.5       | 3      | 6           |

These metrics help visualize how â€œuncertainâ€ or complex each task becomes â€” a measure of **AI entropy**.

---

## ğŸ’» Installation & Setup

### ğŸ§© 1. Clone Repository

```bash
git clone https://github.com/yourusername/nexora.git
cd nexora
```

### ğŸ§° 2. Create Virtual Environment

```bash
python -m venv venv
source venv/bin/activate   # Windows: venv\Scripts\activate
```

### ğŸ“¦ 3. Install Dependencies

```bash
pip install -r requirements.txt
```

### ğŸ§  4. Run Streamlit App

```bash
streamlit run assistant_hub/streamlit_app.py
```

### âš™ï¸ 5. (Optional) Load Fine-Tuned Model

```bash
ollama pull tinyllama-codegen
```

Then reference your `.gguf` model file inside `assistant_hub/models/`.

---

## ğŸ¥ Demo

ğŸ“¹ **[Watch Nexora in Action](#)**

> â€œCan an AI truly learn from its own mistakes?â€
> Nexora plans, codes, and refines its own solutions â€” autonomously and offline.

---

## ğŸ§° Tech Stack

| Category           | Tools & Frameworks         |
| ------------------ | -------------------------- |
| ğŸ’» **Language**    | Python 3.11+               |
| ğŸ¨ **Frontend**    | Streamlit 1.50+            |
| ğŸ¤– **Modeling**    | TinyLlama + LoRA + Unsloth |
| âš™ï¸ **Inference**   | Ollama (GGUF local LLM)    |
| ğŸ”— **Integration** | LangChain / Custom Tools   |

---

## ğŸ”­ Future Improvements

* ğŸ§  Integrate RAG (Retrieval-Augmented Generation) for dynamic research
* ğŸ“Š Build visual dashboard for entropy metrics
* ğŸ§© Add continuous fine-tuning pipeline from collected data
* ğŸ‘¥ Enable collaborative multi-user sessions
* ğŸ§° Add plugin system for custom external tools

---

## ğŸ‘¤ Author

**Ayanda [Your Surname]**
ğŸ’¼ AI Engineer | ML Developer | Indie Researcher
ğŸ“« [LinkedIn](#) â€¢ [Portfolio](#) â€¢ [Email](#)

> *â€œI build AI systems that learn to think.â€*

---

## ğŸ“œ License

This project is open-source and available under the **MIT License**.

---

## ğŸŒŸ Acknowledgments

* **TinyLlama** team for the efficient open-source model
* **sahil2801/CodeAlpaca-20k** for dataset inspiration
* **Unsloth** for simplifying LoRA fine-tuning
* **Streamlit** for enabling rapid, beautiful interfaces

---

## ğŸ§­ Support the Project

If you find **Nexora** inspiring, give it a â­ on GitHub and share your ideas or contributions!
